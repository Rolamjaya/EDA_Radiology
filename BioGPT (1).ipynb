{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b72780f3-4b9e-4dea-93ce-8f9bf90f4421",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e7972-5cde-4942-a836-1694b035d2ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trying BioGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49485b1f-bcfd-4afa-b433-a79e32387245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 110\n",
      "CUDA SETUP: Loading binary /opt/conda/envs/python39/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda110.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python39/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /opt/conda did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    ")\n",
    " \n",
    "import fire\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    " \n",
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize':(10, 7)})\n",
    "sns.set(rc={'figure.dpi':100})\n",
    "sns.set(style='white', palette='muted', font_scale=1.2)\n",
    " \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e16cd4-7349-4b48-81a8-1e992bf561c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf7649528f24d70962604c1f1b35f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
    "model = BioGptForCausalLM.from_pretrained(\"microsoft/biogpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41c2458b-dd39-4f8a-bd96-40a6615eb8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ''' instruction: draft impression of radiology report from this clinical information and findings.\n",
    "\n",
    "clinical information: locally recurrent oral tongue squamous cell carcinoma referred here for consideration of clinical trial participation.\n",
    "\n",
    "findings: There are post-treatment findings in the neck related to partial right glossectomy with mandibulectomy, flap reconstruction, and neck dissection. There is an infiltrative heterogeneous mass in the left masticator, parapharyngeal, and pharyngeal mucosal spaces, with associated left mandible, posterior maxillary sinus wall, and central skull base erosion and extension into the left middle cranial fossa. There is partial opacification of the bilateral maxillary sinuses and complete left tympanomastoid opacification. There is a cluster of prominent left level 6 lymph nodes. The thyroid gland appears unremarkable. The orbits are unremarkable.\n",
    "\n",
    "impression:\n",
    "'''\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b10991fe-82e5-4dc3-85b5-f6b3f3f59378",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    beam_output = model.generate(**inputs,\n",
    "                                min_length=100,\n",
    "                                max_length=2048,\n",
    "                                num_beams=5,\n",
    "                                early_stopping=True\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5128656e-08fa-4a80-98bf-871d0fdf05b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'instruction: draft impression of radiology report from this clinical information and findings. clinical information: locally recurrent oral tongue squamous cell carcinoma referred here for consideration of clinical trial participation. findings: There are post-treatment findings in the neck related to partial right glossectomy with mandibulectomy, flap reconstruction, and neck dissection. There is an infiltrative heterogeneous mass in the left masticator, parapharyngeal, and pharyngeal mucosal spaces, with associated left mandible, posterior maxillary sinus wall, and central skull base erosion and extension into the left middle cranial fossa. There is partial opacification of the bilateral maxillary sinuses and complete left tympanomastoid opacification. There is a cluster of prominent left level 6 lymph nodes. The thyroid gland appears unremarkable. The orbits are unremarkable. impression: a.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(beam_output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf9b93e-011f-4dfc-a4a9-f9b73b554ae0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reading json, obtain the label, convert to DataFrame, create instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b40891c-2670-4b7e-8668-d742201f4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import json\n",
    "\n",
    "gcs_file_system = gcsfs.GCSFileSystem(project=\"capstone\")\n",
    "gcs_json_path = \"gs://radiology-data/report_CT.json\"\n",
    "with gcs_file_system.open(gcs_json_path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30a68149-0374-4fae-82ce-f93187a998f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data.get(\"Report_6\").get(\"findings_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8532a55a-3fb3-4056-a922-fc080ba1c6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'report_id': 6,\n",
       " 'modality': 'CT',\n",
       " 'clinical_information': {'clinical_information': 'locally recurrent oral tongue squamous cell carcinoma referred here for consideration of clinical trial participation.',\n",
       "  'background': {'locally recurrent oral tongue squamous cell carcinoma': {'clinical finding': 'locally recurrent oral tongue squamous cell carcinoma',\n",
       "    'cf_snomed': {'squamous cell carcinoma': 402815007},\n",
       "    'existence': 'pos_dx',\n",
       "    'descriptive_term': 'locally recurrent oral tongue squamous cell',\n",
       "    'observation': 'carcinoma'}}},\n",
       " 'findings_group': {'findings': 'There are post-treatment findings in the neck related to partial right glossectomy with mandibulectomy, flap reconstruction, and neck dissection. There is an infiltrative heterogeneous mass in the left masticator, parapharyngeal, and pharyngeal mucosal spaces, with associated left mandible, posterior maxillary sinus wall, and central skull base erosion and extension into the left middle cranial fossa. There is partial opacification of the bilateral maxillary sinuses and complete left tympanomastoid opacification. There is a cluster of prominent left level 6 lymph nodes. The thyroid gland appears unremarkable. The orbits are unremarkable.',\n",
       "  'findings_sentences': {'Sentence-1': {'report_sid_fin': 55.0,\n",
       "    'sentence_fin': 'there are post-treatment findings in the neck related to partial right glossectomy with mandibulectomy, flap reconstruction, and neck dissection',\n",
       "    'anatomical entity_fin': {'neck': {}},\n",
       "    'location descriptor_fin': ['right'],\n",
       "    'procedure_fin': ['treatment'],\n",
       "    'clinical findings_fin': {'post-treatment': {'clinical finding': 'post-treatment',\n",
       "      'existence': 'pos_dx',\n",
       "      'observation': 'post'},\n",
       "     'mandibulectomy': {'clinical finding': 'mandibulectomy',\n",
       "      'existence': 'pos_dx',\n",
       "      'observation': 'mandibulectomy'},\n",
       "     'flap reconstruction': {'clinical finding': 'flap reconstruction',\n",
       "      'existence': 'pos_dx',\n",
       "      'descriptive_term': 'flap',\n",
       "      'observation': 'reconstruction'},\n",
       "     'neck dissection': {'clinical finding': 'neck dissection',\n",
       "      'existence': 'pos_dx',\n",
       "      'descriptive_term': 'neck',\n",
       "      'observation': 'dissection'}}},\n",
       "   'Sentence-2': {'report_sid_fin': 56.0,\n",
       "    'sentence_fin': 'there is an infiltrative heterogeneous mass in the left masticator, parapharyngeal, and pharyngeal mucosal spaces, with associated left mandible, posterior maxillary sinus wall, and central skull base erosion and extension into the left middle cranial fossa',\n",
       "    'anatomical entity_fin': {'mandible': {'location descriptor': 'left'},\n",
       "     'maxillary sinus': {'location descriptor': 'posterior'},\n",
       "     'wall': {},\n",
       "     'skull': {'location descriptor': 'central'},\n",
       "     'base': {},\n",
       "     'middle': {'location descriptor': 'left'}},\n",
       "    'location descriptor_fin': ['left', 'posterior', 'central'],\n",
       "    'clinical findings_fin': {'infiltrative heterogeneous mass': {'clinical finding': 'infiltrative heterogeneous mass',\n",
       "      'existence': 'pos_dx',\n",
       "      'descriptive_term': 'infiltrative heterogeneous',\n",
       "      'observation': 'mass'},\n",
       "     'central skull base erosion': {'clinical finding': 'central skull base erosion',\n",
       "      'existence': 'pos_dx',\n",
       "      'descriptive_term': 'central skull base',\n",
       "      'observation': 'erosion'}}},\n",
       "   'Sentence-3': {'report_sid_fin': 57.0,\n",
       "    'sentence_fin': 'there is partial opacification of the bilateral maxillary sinuses and complete left tympanomastoid opacification',\n",
       "    'location descriptor_fin': ['bilateral', 'left'],\n",
       "    'clinical findings_fin': {'partial opacification': {'clinical finding': 'partial opacification',\n",
       "      'existence': 'pos_dx',\n",
       "      'descriptive_term': 'partial',\n",
       "      'observation': 'opacification',\n",
       "      'strength_term': 'partial'},\n",
       "     'complete left tympanomastoid opacification': {'clinical finding': 'complete left tympanomastoid opacification',\n",
       "      'existence': 'pos_dx',\n",
       "      'descriptive_term': 'complete left tympanomastoid',\n",
       "      'observation': 'opacification'}}},\n",
       "   'Sentence-4': {'report_sid_fin': 58.0,\n",
       "    'sentence_fin': 'there is a cluster of prominent left level 6 lymph nodes',\n",
       "    'location descriptor_fin': ['left'],\n",
       "    'clinical findings_fin': {'prominent left level 6 lymph nodes': {'clinical finding': 'prominent left level 6 lymph nodes',\n",
       "      'existence': 'pos_dx',\n",
       "      'descriptive_term': 'prominent left level 6 lymph',\n",
       "      'observation': 'node',\n",
       "      'strength_term': 'prominent'}}},\n",
       "   'Sentence-5': {'report_sid_fin': 59.0,\n",
       "    'sentence_fin': 'the thyroid gland appears unremarkable',\n",
       "    'anatomical entity_fin': {'thyroid gland': {}},\n",
       "    'clinical findings_fin': {'thyroid gland appears unremarkable': {'clinical finding': 'thyroid gland appears unremarkable'}}},\n",
       "   'Sentence-6': {'report_sid_fin': 60.0,\n",
       "    'sentence_fin': 'the orbits are unremarkable',\n",
       "    'anatomical entity_fin': {'orbits': {}},\n",
       "    'clinical findings_fin': {'orbits are unremarkable': {'clinical finding': 'orbits are unremarkable'}}}}},\n",
       " 'impression_group': {'impression': 'Postoperative findings with evidence of recurrent tumor in the left masticator, parapharyngeal, and pharyngeal mucosal spaces, with associated left mandible, posterior maxillary sinus wall, and central skull base erosion and extension into the left middle cranial fossa and overlying skin of the face. Prominent left level 6 lymph nodes may represent metastatic disease, but are nonspecific.',\n",
       "  'impression_sentences': {'Sentence-1': {'report_sid': 15.0,\n",
       "    'sentence': 'postoperative findings with evidence of recurrent tumor in the left masticator, parapharyngeal, and pharyngeal mucosal spaces, with associated left mandible, posterior maxillary sinus wall, and central skull base erosion and extension into the left middle cranial fossa and overlying skin of the face',\n",
       "    'anatomical entity': {'mandible': {'location descriptor': 'left'},\n",
       "     'maxillary sinus': {'location descriptor': 'posterior'},\n",
       "     'wall': {},\n",
       "     'skull': {'location descriptor': 'central'},\n",
       "     'base': {},\n",
       "     'middle': {'location descriptor': 'left'},\n",
       "     'skin': {},\n",
       "     'face': {}},\n",
       "    'location descriptor': ['left', 'posterior', 'central'],\n",
       "    'clinical findings': {'recurrent tumor': {'clinical finding': 'recurrent tumor',\n",
       "      'cf_snomed': {'recurrent tumor': 25173007},\n",
       "      'existence': 'pos_dx',\n",
       "      'descriptive_term': 'recurrent',\n",
       "      'observation': 'tumor'},\n",
       "     'central skull base erosion': {'clinical finding': 'central skull base erosion',\n",
       "      'existence': 'pos_dx',\n",
       "      'descriptive_term': 'central skull base',\n",
       "      'observation': 'erosion'}}},\n",
       "   'Sentence-2': {'report_sid': 16.0,\n",
       "    'sentence': 'prominent left level 6 lymph nodes may represent metastatic disease, but are nonspecific',\n",
       "    'location descriptor': ['left'],\n",
       "    'clinical findings': {'prominent left level 6 lymph nodes': {'clinical finding': 'prominent left level 6 lymph nodes',\n",
       "      'existence': 'pos_dx',\n",
       "      'descriptive_term': 'prominent left level 6 lymph',\n",
       "      'observation': 'node',\n",
       "      'strength_term': 'prominent'},\n",
       "     'metastatic disease': {'clinical finding': 'metastatic disease',\n",
       "      'cf_snomed': {'disease': 64572001},\n",
       "      'existence': 'unc_dx',\n",
       "      'descriptive_term': 'metastatic',\n",
       "      'observation': 'disease'}}}}}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.get(\"Report_6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "920f4089-c4f4-411b-b909-0e83391c3d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['report_sid_fin', 'sentence_fin', 'anatomical entity_fin', 'location descriptor_fin', 'procedure_fin', 'clinical findings_fin'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.get('findings_sentences').get('Sentence-1').keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f9ae7ce-a754-4a5d-ab62-d2dc06bb69d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'report_sid_fin': 60.0,\n",
       " 'sentence_fin': 'the orbits are unremarkable',\n",
       " 'anatomical entity_fin': {'orbits': {}},\n",
       " 'clinical findings_fin': {'orbits are unremarkable': {'clinical finding': 'orbits are unremarkable'}}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.get('findings_sentences').get('Sentence-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f45badc1-55a7-4283-8e28-66756db75cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'report_sid_fin': 55.0,\n",
       " 'sentence_fin': 'there are post-treatment findings in the neck related to partial right glossectomy with mandibulectomy, flap reconstruction, and neck dissection',\n",
       " 'anatomical entity_fin': {'neck': {}},\n",
       " 'location descriptor_fin': ['right'],\n",
       " 'procedure_fin': ['treatment'],\n",
       " 'clinical findings_fin': {'post-treatment': {'clinical finding': 'post-treatment',\n",
       "   'existence': 'pos_dx',\n",
       "   'observation': 'post'},\n",
       "  'mandibulectomy': {'clinical finding': 'mandibulectomy',\n",
       "   'existence': 'pos_dx',\n",
       "   'observation': 'mandibulectomy'},\n",
       "  'flap reconstruction': {'clinical finding': 'flap reconstruction',\n",
       "   'existence': 'pos_dx',\n",
       "   'descriptive_term': 'flap',\n",
       "   'observation': 'reconstruction'},\n",
       "  'neck dissection': {'clinical finding': 'neck dissection',\n",
       "   'existence': 'pos_dx',\n",
       "   'descriptive_term': 'neck',\n",
       "   'observation': 'dissection'}}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.get('findings_sentences').get('Sentence-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e67775e-f39e-44dc-b3d5-44e38a518850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'report_sid_fin': 58.0,\n",
       " 'sentence_fin': 'there is a cluster of prominent left level 6 lymph nodes',\n",
       " 'location descriptor_fin': ['left'],\n",
       " 'clinical findings_fin': {'prominent left level 6 lymph nodes': {'clinical finding': 'prominent left level 6 lymph nodes',\n",
       "   'existence': 'pos_dx',\n",
       "   'descriptive_term': 'prominent left level 6 lymph',\n",
       "   'observation': 'node',\n",
       "   'strength_term': 'prominent'}}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.get('findings_sentences').get('Sentence-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3f8b4cf-1ea6-4bdf-9541-b1c5e748ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_report = []\n",
    "for key, value in data.items():\n",
    "    report = dict()\n",
    "    report_id = value['report_id']\n",
    "    try:\n",
    "        clinical_information = value['clinical_information']['clinical_information']\n",
    "    except KeyError:\n",
    "        clinical_information = \"\" \n",
    "    findings_group = value['findings_group']['findings']\n",
    "    impression_group = value['impression_group']['impression']\n",
    "    full_report.append(report)\n",
    "    report['report_id'] = report_id\n",
    "    report['clinical_information'] = clinical_information\n",
    "    report['findings'] = findings_group\n",
    "    report['impression'] = impression_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19c23b90-04e1-4d81-83fb-8592bfc7ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CT_report = pd.DataFrame(full_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf4b3d7a-db54-4cdd-bddf-33fe46d28ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_id</th>\n",
       "      <th>clinical_information</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>locally recurrent oral tongue squamous cell ca...</td>\n",
       "      <td>There are post-treatment findings in the neck ...</td>\n",
       "      <td>Postoperative findings with evidence of recurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>64 years old male with history of left humerus...</td>\n",
       "      <td>. Scattered pulmonary micronodules, some which...</td>\n",
       "      <td>No evidence of metastatic disease.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>female, 57 years old, with subarachnoid hemorr...</td>\n",
       "      <td>A large coil mass is redemonstrated in the reg...</td>\n",
       "      <td>Redemonstration of a large coil mass situated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>male, 66 years old, status post subdural hemor...</td>\n",
       "      <td>Findings are redemonstrated compatible with su...</td>\n",
       "      <td>No significant change in the size of bilateral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>empty.</td>\n",
       "      <td>The ventricles and sulci are within normal lim...</td>\n",
       "      <td>No acute intracranial hemorrhage.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   report_id                               clinical_information   \n",
       "0          6  locally recurrent oral tongue squamous cell ca...  \\\n",
       "1          7  64 years old male with history of left humerus...   \n",
       "2         13  female, 57 years old, with subarachnoid hemorr...   \n",
       "3         14  male, 66 years old, status post subdural hemor...   \n",
       "4         15                                             empty.   \n",
       "\n",
       "                                            findings   \n",
       "0  There are post-treatment findings in the neck ...  \\\n",
       "1  . Scattered pulmonary micronodules, some which...   \n",
       "2  A large coil mass is redemonstrated in the reg...   \n",
       "3  Findings are redemonstrated compatible with su...   \n",
       "4  The ventricles and sulci are within normal lim...   \n",
       "\n",
       "                                          impression  \n",
       "0  Postoperative findings with evidence of recurr...  \n",
       "1                 No evidence of metastatic disease.  \n",
       "2  Redemonstration of a large coil mass situated ...  \n",
       "3  No significant change in the size of bilateral...  \n",
       "4                  No acute intracranial hemorrhage.  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CT_report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67cb7390-692a-4c46-a94d-efa085237c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_report[\"clinical_information\"] = CT_report[\"clinical_information\"].apply(lambda x: \"\" if x == \"empty.\" else x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8b5f06f-ec37-4067-b7bd-ad431e92144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_report[\"findings\"] = CT_report[\"findings\"].apply(lambda x: \"\" if x == \"empty\" else x) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d222639f-ab81-46df-8e74-ae95cdd72601",
   "metadata": {},
   "source": [
    "### Change it back to JSON instruction format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d6e9de6-e35c-4375-b943-dcdb683c4269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Find the conclusion from the findings obtained in the radiology examination',\n",
       " 'input': 'Background of the patient is locally recurrent oral tongue squamous cell carcinoma referred here for consideration of clinical trial participation. Examination findings is There are post-treatment findings in the neck related to partial right glossectomy with mandibulectomy, flap reconstruction, and neck dissection. There is an infiltrative heterogeneous mass in the left masticator, parapharyngeal, and pharyngeal mucosal spaces, with associated left mandible, posterior maxillary sinus wall, and central skull base erosion and extension into the left middle cranial fossa. There is partial opacification of the bilateral maxillary sinuses and complete left tympanomastoid opacification. There is a cluster of prominent left level 6 lymph nodes. The thyroid gland appears unremarkable. The orbits are unremarkable.',\n",
       " 'output': 'Postoperative findings with evidence of recurrent tumor in the left masticator, parapharyngeal, and pharyngeal mucosal spaces, with associated left mandible, posterior maxillary sinus wall, and central skull base erosion and extension into the left middle cranial fossa and overlying skin of the face. Prominent left level 6 lymph nodes may represent metastatic disease, but are nonspecific.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_data = [\n",
    "    {\n",
    "        \"instruction\": \"Find the conclusion from the findings obtained in the radiology examination\",\n",
    "        \"input\": \"Background of the patient is \" + row_report[\"clinical_information\"] + \" Examination findings is \" + row_report[\"findings\"],\n",
    "        \"output\": row_report[\"impression\"]\n",
    "    }\n",
    "    for row_report in CT_report.to_dict(orient=\"records\")\n",
    "]\n",
    " \n",
    "dataset_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "198074c0-3366-4dde-8831-d7acfc9574e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"alpaca-radiology-report.json\", \"w\") as f:\n",
    "    json.dump(dataset_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d4a2329-ff3a-42aa-b86c-b915899527b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/tmp/ipykernel_12982/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">542597409.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/var/tmp/ipykernel_12982/542597409.py'</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/python39/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2740</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2737 │   │   │   │   │   </span>key: device_map[key] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> key <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> device_map.keys() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> key <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> modu  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2738 │   │   │   │   </span>}                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2739 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"cpu\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> device_map_without_lm_head.values() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"disk\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> device_map_  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2740 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2741 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2742 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">Some modules are dispatched on the CPU or the disk. Make sure yo</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2743 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">the quantized model. If you want to dispatch the model on the CP</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>\n",
       "                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to \n",
       "fit\n",
       "                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n",
       "                        these modules in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-bit, you need to set `<span style=\"color: #808000; text-decoration-color: #808000\">load_in_8bit_fp32_cpu_offload</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>` and pass a \n",
       "custom\n",
       "                        `device_map` to `from_pretrained`. Check\n",
       "                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-</span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">cpu-and-gpu</span>\n",
       "                        for more details.\n",
       "                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/tmp/ipykernel_12982/\u001b[0m\u001b[1;33m542597409.py\u001b[0m:\u001b[94m3\u001b[0m in \u001b[92m<module>\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/var/tmp/ipykernel_12982/542597409.py'\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/python39/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.py\u001b[0m:\u001b[94m2740\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2737 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mkey: device_map[key] \u001b[94mfor\u001b[0m key \u001b[95min\u001b[0m device_map.keys() \u001b[94mif\u001b[0m key \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m modu  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2738 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m}                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2739 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mcpu\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m device_map_without_lm_head.values() \u001b[95mor\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mdisk\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m device_map_  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2740 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2741 \u001b[0m\u001b[2;90m│   │   │   │   │   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2742 \u001b[0m\u001b[2;33m│   │   │   │   │   │   \u001b[0m\u001b[33mSome modules are dispatched on the CPU or the disk. Make sure yo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2743 \u001b[0m\u001b[2;33m│   │   │   │   │   │   \u001b[0m\u001b[33mthe quantized model. If you want to dispatch the model on the CP\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0m\n",
       "                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to \n",
       "fit\n",
       "                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n",
       "                        these modules in \u001b[1;36m32\u001b[0m-bit, you need to set `\u001b[33mload_in_8bit_fp32_cpu_offload\u001b[0m=\u001b[3;92mTrue\u001b[0m` and pass a \n",
       "custom\n",
       "                        `device_map` to `from_pretrained`. Check\n",
       "                        \u001b[4;94mhttps://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-\u001b[0m\n",
       "\u001b[4;94mcpu-and-gpu\u001b[0m\n",
       "                        for more details.\n",
       "                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_MODEL = \"decapoda-research/llama-7b-hf\"\n",
    " \n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    " \n",
    "tokenizer = LlamaTokenizer.from_pretrained(BASE_MODEL)\n",
    " \n",
    "tokenizer.pad_token_id = (\n",
    "    0  # unk. we want this to be different from the eos token\n",
    ")\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "933ddbd3-ff26-4f30-8977-53c253c81748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/jupyter/.cache/huggingface/datasets/json/default-e79d2a9aec3213b9/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f655a1c86644c581d9e42c3d77aac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output'],\n",
       "    num_rows: 246824\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files=\"alpaca-radiology-report.json\")\n",
    "data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ceba72-02f5-42a0-ad55-16f8d90c304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    \n",
    "    return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.  # noqa: E501\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "### Input:\n",
    "{data_point[\"input\"]}\n",
    "### Response:\n",
    "{data_point[\"output\"]}\"\"\"\n",
    " \n",
    " \n",
    "def tokenize(prompt, add_eos_token=True):\n",
    "    CUTOFF_LEN = 900\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=CUTOFF_LEN,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    if (\n",
    "        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "        and len(result[\"input_ids\"]) < CUTOFF_LEN\n",
    "        and add_eos_token\n",
    "    ):\n",
    "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        result[\"attention_mask\"].append(1)\n",
    " \n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    " \n",
    "    return result\n",
    " \n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(data_point)\n",
    "    tokenized_full_prompt = tokenize(full_prompt)\n",
    "    return tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a391e5-ca70-42af-a29c-a2b5f6647af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/jupyter/.cache/huggingface/datasets/json/default-e79d2a9aec3213b9/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-9b7bddeeeb9abf3e.arrow and /home/jupyter/.cache/huggingface/datasets/json/default-e79d2a9aec3213b9/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-ebd6124ff0bdeb8e.arrow\n",
      "Loading cached processed dataset at /home/jupyter/.cache/huggingface/datasets/json/default-e79d2a9aec3213b9/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-3dc938128a6bdc30.arrow\n",
      "Loading cached processed dataset at /home/jupyter/.cache/huggingface/datasets/json/default-e79d2a9aec3213b9/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-810b0b36605039c6.arrow\n"
     ]
    }
   ],
   "source": [
    "train_val = data[\"train\"].train_test_split(\n",
    "    test_size=200, shuffle=True, seed=42\n",
    ")\n",
    "train_data = (\n",
    "    train_val[\"train\"].map(generate_and_tokenize_prompt)\n",
    ")\n",
    "val_data = (\n",
    "    train_val[\"test\"].map(generate_and_tokenize_prompt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "10a1305e-597c-4f90-bfc6-8e14861bfc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18147"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a5c0c9-e70f-4305-a0eb-fce69a28be82",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9dffb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 110\n",
      "CUDA SETUP: Loading binary /opt/conda/envs/python39/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda110.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python39/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /opt/conda did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    ")\n",
    " \n",
    "import fire\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    " \n",
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize':(10, 7)})\n",
    "sns.set(rc={'figure.dpi':100})\n",
    "sns.set(style='white', palette='muted', font_scale=1.2)\n",
    " \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51fb89aa-8108-47de-b4ec-92f1da8e2198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/jupyter/.cache/huggingface/datasets/json/default-c0f400b185080c8b/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6cef881eb3a4ca684d95bf3920d313c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output'],\n",
       "    num_rows: 61706\n",
       "})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files=\"quarter_radiology.json\")\n",
    "data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9a841420-05f4-4bcf-8ad5-71be8474fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    \n",
    "    return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "### Input:\n",
    "{data_point[\"input\"]}\n",
    "### Response:\n",
    "{data_point[\"output\"]}\"\"\"\n",
    " \n",
    " \n",
    "def tokenize(prompt, add_eos_token=True):\n",
    "    CUTOFF_LEN = 256\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=CUTOFF_LEN,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    if (\n",
    "        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "        and len(result[\"input_ids\"]) < CUTOFF_LEN\n",
    "        and add_eos_token\n",
    "    ):\n",
    "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        result[\"attention_mask\"].append(1)\n",
    " \n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    " \n",
    "    return result\n",
    " \n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(data_point)\n",
    "    tokenized_full_prompt = tokenize(full_prompt)\n",
    "    return tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9b0b6cf-5d57-48c1-a8d7-c3ee6ee90997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/jupyter/.cache/huggingface/datasets/json/default-c0f400b185080c8b/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-fdd8949182cd5e1e.arrow and /home/jupyter/.cache/huggingface/datasets/json/default-c0f400b185080c8b/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-9ce7b22f198aa447.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61506 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_val = data[\"train\"].train_test_split(\n",
    "    test_size=200, shuffle=True, seed=42\n",
    ")\n",
    "train_data = (\n",
    "    train_val[\"train\"].map(generate_and_tokenize_prompt)\n",
    ")\n",
    "val_data = (\n",
    "    train_val[\"test\"].map(generate_and_tokenize_prompt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ff01401-70ab-43e2-81a8-947ee62d6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LORA_R = 8\n",
    "LORA_ALPHA = 16\n",
    "LORA_DROPOUT= 0.05\n",
    "LORA_TARGET_MODULES = [\n",
    "    \"q_proj\",\n",
    "    \"v_proj\",\n",
    "]\n",
    " \n",
    "BATCH_SIZE = 128\n",
    "MICRO_BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
    "LEARNING_RATE = 3e-4\n",
    "TRAIN_STEPS = 300\n",
    "OUTPUT_DIR = \"experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f8b95cf7-ac65-4687-9014-a2c1a9c11afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 786432 || all params: 347549696 || trainable%: 0.22627900672944337\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_int8_training(model)\n",
    "config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=LORA_TARGET_MODULES,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5b8af94-fa4f-421d-b438-3adda3ed6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "95629dd9-ba79-4ff1-8aa4-6f1b7d055c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    warmup_steps=100,\n",
    "    max_steps=TRAIN_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    optim=\"adamw_torch\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_steps=50,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "72ad4a7c-83f7-41bb-8517-540909e34ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DataCollatorForSeq2Seq(\n",
    "    tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94a707ca-318a-431d-b6cd-adec573eebeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python39/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23067' max='23067' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23067/23067 3:26:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.612600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.899700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.841700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.797800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.767300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.733200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.724800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.702400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.677500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.674700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.661000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.646200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.644800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.632400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.624300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.606700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.598500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.606900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.601600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.600200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.588900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>1.571700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.576600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>1.563400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.567600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>1.567100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.582200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>1.554700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.563300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>1.549400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.553200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>1.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.545600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>1.562300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>1.542400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>1.546900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.552200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>1.548800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>1.544800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>1.542200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>1.549900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>1.542200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "model.config.use_cache = False\n",
    "old_state_dict = model.state_dict\n",
    "model.state_dict = (\n",
    "    lambda self, *_, **__: get_peft_model_state_dict(\n",
    "        self, old_state_dict()\n",
    "    )\n",
    ").__get__(model, type(model))\n",
    " \n",
    "model = torch.compile(model)\n",
    " \n",
    "trainer.train()\n",
    "model.save_pretrained(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "44870536-5f76-4b57-92c1-536b53e697ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51f8cc97ee04f69b91117afaec15a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57470baf-1bb0-4e1d-8b69-1f2515dbb5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d322338ac0428ab766266f9817d9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67280aea9c2499f810ef9acf4d47392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.bin:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/rlmjy/biogpt_finetuned_1/commit/a8980cab20b6c70ee40f0f1eea19eec0c9ff77a0', commit_message='Upload model', commit_description='', oid='a8980cab20b6c70ee40f0f1eea19eec0c9ff77a0', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"rlmjy/biogpt_finetuned_1\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d2e3cdf5-efc1-41c8-9273-eb53edadda10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Find the conclusion from the findings obtained in the radiology examination',\n",
       " 'input': 'Background of the patient is . Malignant neoplasm of head, face, and neck. History of hnc and capillary refill time, compare to previous measurements. Examination findings is Within the suprahyoid neck on the basis of size criteria for lymphadenopathy no lymphadenopathy is appreciated. Within the infrahyoid neck on the basis of size criteria for lymphadenopathy no lymphadenopathy is appreciated. Within the visceral space the thyroid gland appears intact. The airway appears patent. The visualized intracranial structures which include the posterior fossa are intact. The visualized portions of the orbits are intact. The paranasal sinuses are clear. The mastoid air cells are clear. The parotid and the submandibular glands appear intact. The visualized lung apices appear clear. The carotid and vertebral vasculature visualized on this exam appears intact. The cervical vertebral bodies in general are intact. There are multilevel degenerative changes present in the cervical spine with multilevel facet hypertrophy and uncovertebral osteophytes. Large right-sided uncovertebral osteophytes are present at C3-4. It is stable relative to the prior exam.',\n",
       " 'output': 'No evidence for local recurrence or neck lymphadenopathy on the basis of CT size criteria for lymphadenopathy.'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Opening JSON file\n",
    "with open('alpaca-radiology-report.json', 'r') as openfile:\n",
    "\n",
    "    # Reading from json file\n",
    "    json_object = json.load(openfile)\n",
    "\n",
    "json_object[-128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d02ccb58-1525-4f80-81e6-e127e1702413",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_object = len(json_object)//32\n",
    "test_data = json_object[-len_object:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e462f0a5-4810-4dd4-b3c7-3993c72b1ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7713"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ba20895c-fd17-4814-bc04-70bb1c242857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No evidence for local recurrence or neck lymphadenopathy on the basis of CT size criteria for lymphadenopathy.'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_object[-128]['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "99d91c50-4134-49d8-a8bb-db08ce0f37ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(s):\n",
    "    text = s.split(\"Response:\")[-1].split(\"</s>\")[0].strip()\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ee909083-534b-4511-91ba-8e22477dd8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_test(data_point):\n",
    "    \n",
    "    return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "### Input:\n",
    "{data_point[\"input\"]}\n",
    "### Response: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2fabaf6f-a339-4eda-9be4-e53bfac89d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18147"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8706bc24-827f-4023-9528-6dff08c18e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "31145600-501d-45d3-91c6-625ffb45b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.15,\n",
    ")\n",
    "\n",
    "for test in test_data[5391:7713]:\n",
    "    PROMPT = generate_prompt_test(test)\n",
    "    original_output = test['output']\n",
    "    from transformers import GenerationConfig\n",
    "    inputs = tokenizer(\n",
    "        PROMPT,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs[\"input_ids\"].cuda()\n",
    "    score = []\n",
    "    generated_text = []\n",
    "    for _ in range(5):\n",
    "        generation_output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=128,\n",
    "        )\n",
    "        text = \"\"\n",
    "        for s in generation_output.sequences:\n",
    "                text = text + tokenizer.decode(s)\n",
    "        hypothesis = get_output(text)\n",
    "\n",
    "        score_single = rouge_scorer.get_scores(\n",
    "        hyps=hypothesis,\n",
    "        refs=original_output,\n",
    "        )\n",
    "        score.append(score_single[0][\"rouge-l\"][\"f\"])\n",
    "        generated_text.append(hypothesis)\n",
    "    all_score.append(score)\n",
    "    all_generated_text.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "4ca13961-cadc-4547-833e-a3d41f941573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7713"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3b720fa6-b934-431a-a862-b040f07049f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(hypo, ref):\n",
    "    score_single = rouge_scorer.get_scores(\n",
    "        hyps=hypo,\n",
    "        refs=ref,\n",
    "        )\n",
    "    return score_single[0][\"rouge-l\"][\"f\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ccd9b-3611-4bc7-9719-f947e0a15e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"list_score\", \"w\") as fp:\n",
    "    json.dump(all_score, fp)\n",
    "    \n",
    "with open(\"list_score\", \"w\") as fp:\n",
    "    json.dump(all_generated_text, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea44bbf-5009-4f52-868d-07de2ab416fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_score = []\n",
    "for n, test in enumerate(test_data):\n",
    "    score = []\n",
    "    original_output = test['output']\n",
    "    \n",
    "    for hypo in all_generated_text[n]:\n",
    "        score.append(get_score(hypo, original_output))\n",
    "    all_score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c134f726-32b1-403f-95fd-f2f56015fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rouge_five = pd.DataFrame(all_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ed3b506a-11b9-43ef-adb0-1cf543e78b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_rouge = rouge_five.apply(np.max, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6ec87c0f-ea80-4dee-9882-0548fbe8dec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7713"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rouge_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "eff79c0e-db38-4ccc-9a31-744fe9ba4d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAJOCAYAAABbbP0XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAziElEQVR4nO3df3DU9Z348deGBAg/NFGQCEq1OgFEqaDY6vWXQqG9OtJyKKLoV0DRQetw2uvo1WuveB6cP04821psAX8gYK0WqG3VlmtvOm1PUQFRxI5KTAlGtEIVCQnIfv/oZI+YoCx5h03g8ZhxEj773g/vXd5m95nPZ3cz2Ww2GwAAALRKUaEnAAAAcCAQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJFBc6Am0R6eeemo0NDRE7969Cz0VAACggN58883o3LlzPP300x851pGrFtTX18fOnTsLPY2IiMhms1FfXx/ZbLbQU6GDsGbIlzVDvqwZ8mXNkK/2tGZ27twZ9fX1ezXWkasWHHHEERERsXz58gLPJGLbtm3x4osvxqBBg6Jbt26Fng4dgDVDvqwZ8mXNkC9rhny1pzUzYsSIvR7ryBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFdwACopKYlMJlPoaQAAHFSKCz0BIK1MJhMnnDA4ios7FXoq7dKuXdkoKhKeAEB64goOQMXFneLmB1+L6k31hZ5Ku9L/iC7xjfEfK/Q0AIADlLiCA1T1pvp4ZWNdoacBAHDQ8JorAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJFCcz+Cqqqr42c9+Fr///e/jz3/+c7z33nvRt2/fOOOMM2Lq1KlxxBFHNBm/c+fOmDdvXjz88MNRU1MTZWVlMWLEiJg+fXqUl5c32//mzZtj9uzZsXz58tiyZUv069cvxo0bF5MmTYri4uZTXbduXcyePTueeeaZ2LFjR1RWVsbUqVNj5MiRed4NAAAArZNXXP3kJz+JBx54IM4888z40pe+FF27do1Vq1bFwoULY9myZbFo0aI47rjjcuOvv/76WLZsWZx55pkxZcqU2LBhQ9x7773x7LPPxoMPPhjdunXLjd26dWtMnDgx1q9fHxdccEEMGDAgVqxYEbfeemu8+uqrMXPmzCZzWbduXUyYMCE6d+4ckyZNivLy8li2bFlceeWVMXPmzBg7dmwr7xoAAIC9l1dcjR49OqZOnRqHHHJIbtv48ePj5JNPjm9961vxX//1X3HHHXdERMQf//jHWLZsWZx11llx11135cYPHjw4rr766pg3b15cddVVue1z586Nl19+Oa677rqYNGlSRESce+650bNnz1iwYEGMHTs2hg8fnht/4403Rl1dXdx3331x0kknRUTEuHHj4rzzzouZM2fGqFGjokePHvtwlwAAAOQvr9dcnXTSSU3CqtGXv/zliIh46aWXctuWLl0aEZELpUajR4+Ofv365S7ffXxpaWlMmDChyfbG6y9ZsiS3bcOGDfH000/H8OHDc2EVEVFSUhIXXXRRvPPOO7F8+fJ8bhoAAECrJHlDizfeeCMiInr16pXbtnr16igqKoqTTz652fihQ4dGdXV1bNmyJSIi3nrrraipqYmBAwdG165dm4w96qijonfv3vHcc8/ltjV+P2zYsBb3HRGxZs2aVt0mAACAfOR1WuCeNJ4KuPvrnGpra6O8vDw6d+7cbHyfPn1yY8rKyqK2tjYiIioqKlrcf0VFRVRXVzfZ9+77+eDY3cfsq2w2G9u2bWvVPlKoq6tr8hU+SkNDQ5SWlhZ6Gu1aXV1dZLPZQk+j3fBzhnxZM+TLmiFf7WnNZLPZyGQyezW21XH1gx/8IB5//PEYOXJkfPWrX81t3759exx66KEtXqdLly65Mbt/bSnEGsfvfsc2ft/S+MZ9t/YfoqGhIV588cVW7SOlqqqqQk+BDqK0tDTKysoKPY12bf369e3ih3V74+cM+bJmyJc1Q77aw5ppaGjINcZHaVVc3XvvvXH77bfHaaedFrfeemuTouvatWs0NDS0eL36+vrcmN2/ftj43X8T3/h9S+Mb993a39x37tw5Bg0a1Kp9pFBXVxdVVVVxzDHHOBrBXtnT/0f8n2OPPdaRq934OUO+rBnyZc2Qr/a0ZvZ0AKgl+xxX8+fPj1mzZsXpp58ed911V7MbXVFREVVVVdHQ0NBsQo2v0Wo8he+jTuWrra1tcgpg4/jG/Xxw7O5j9lUmk2nyVvGFVlpa2q7mQ/u1t4etD2aF/iHdXvk5Q76sGfJlzZCv9rBm8nlutU9vaHH33XfHrFmz4jOf+UzMmTOnxScqQ4YMiV27dsXq1aubXbZy5cro379/7tSlXr16Rd++fWPdunW5UwQb1dTUxJtvvhlDhgzJbWt8h8CVK1c22/eqVauajAEAANgf8o6rH/zgB3HbbbfFmWeeGd///vf3eP7hmDFjIiJi3rx5TbY/8cQTUVNTk7u80TnnnBN1dXWxaNGiJtvnz5/fZH8REUcffXQMGzYsnnrqqXj++edz23fu3Bn3339/9OzZM84666x8bxoAAMA+y+u0wAceeCBuv/326NWrV3zhC1+IX/7yl00u7969e4wcOTIiIs4444w4++yz49FHH40rrrgiRowYERs2bIh77rknjj/++Gaff3XZZZfF448/HrfcckvU1NTEgAEDYsWKFbF06dIYM2ZMnHbaaU3G33DDDTFx4sSYMmVKXHLJJVFeXh5Lly6NF154IW666abo2bPnvtwfAAAA+ySvuGr87Ki33nor/vmf/7nZ5f369cvFVUTErFmzorKyMh555JH4zne+E2VlZTFmzJiYPn16dO/evcl1e/ToEQsXLozZs2fHY489FosXL45+/frFtddeG5MnT272dw0ePDgWLVoUt99+e8ydOzd27NgRlZWVceedd8aoUaPyuVkAAACtlldczZo1K2bNmrXX40tKSuLyyy+Pyy+/fK/GH3bYYTFjxoyYMWPGXo0fOHBgzJkzZ6/nAwAA0Fb26Q0tAAAAaEpcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIK4CCXyWSipKSk0NMAgA5PXAEHjfIexbFrV7bQ02h3SktL44QTBkcmkyn0VACgQysu9AQA9pfupZ2iqCgTNz/4WlRvqi/0dNqN/kd0iW+M/1js2FHomQBAxyaugINO9ab6eGVjXaGnAQAcYJwWCAAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACRQnO8V7r777li7dm2sXbs2qquro6ioKNauXdvi2CeffDIuvvjiFi8rKyuLJ598stn2zZs3x+zZs2P58uWxZcuW6NevX4wbNy4mTZoUxcXNp7tu3bqYPXt2PPPMM7Fjx46orKyMqVOnxsiRI/O9aQAAAPss77i67bbb4pBDDolBgwbFtm3b4u233/7I64wfPz5OOeWUJtu6dOnSbNzWrVtj4sSJsX79+rjgggtiwIABsWLFirj11lvj1VdfjZkzZzYZv27dupgwYUJ07tw5Jk2aFOXl5bFs2bK48sorY+bMmTF27Nh8bx4AAMA+yTuufvWrX0X//v0jIuKiiy7aq7g6+eSTY8yYMR85bu7cufHyyy/HddddF5MmTYqIiHPPPTd69uwZCxYsiLFjx8bw4cNz42+88caoq6uL++67L0466aSIiBg3blycd955MXPmzBg1alT06NEj35sIAACQt7xfc9UYVvmqq6uL7du3f+iYpUuXRmlpaUyYMKHJ9sbQWrJkSW7bhg0b4umnn47hw4fnwioioqSkJC666KJ45513Yvny5fs0VwAAgHzlfeRqX9x0001x/fXXR0RERUVFnHPOOTFt2rQoLS3NjXnrrbeipqYmhg4dGl27dm1y/aOOOip69+4dzz33XG5b4/fDhg1r9vcNHTo0IiLWrFmzV0fMWpLNZmPbtm37dN2U6urqmnyFj9LQ0NDk/y3YW/X19ZHNZgs9DToAj03ky5ohX+1pzWSz2chkMns1tk3jqri4OD7/+c/HZz/72TjyyCPj7bffjl//+tdx9913xx/+8IdYsGBB7klgbW1tRPwtvlpSUVER1dXVuT83ju/Tp0+LY3cfsy8aGhrixRdf3Ofrp1ZVVVXoKdBBlJaWRllZWaGnQQe0cePGdvEgRsfhsYl8WTPkqz2smYaGhhbfL6IlbRpXp5xySsyZM6fJtnHjxsWtt94aP/zhD+P++++PqVOnRkTkThns3Llzi/vq0qVLkwf9xu9bGt9441vzJKFz584xaNCgfb5+KnV1dVFVVRXHHHOMoxHslYaGhkJPgQ6qb9++e/wZDLvz2ES+rBny1Z7WTD6PjfvltMAPmjZtWsydOzd+85vf5OKq8VTAPT0xrK+vb3LHNn7f0vj6+vomY/ZFJpOJbt267fP1UystLW1X86H92tvD1vBBXbp0KfgDGB2LxybyZc2Qr/awZvJ5blWQDxHu1q1bHH744U3eafCjTuWrra1tcgpg4/g33nijxbG7jwEAAGhrBYmrrVu3xltvvRW9evXKbevVq1f07ds31q1b1+xdBWtqauLNN9+MIUOG5LY1vkPgypUrm+1/1apVTcYAAAC0tTaNq82bNzfbls1m4+abb45sNhsjR45sctk555wTdXV1sWjRoibb58+fHxHR5J3/jj766Bg2bFg89dRT8fzzz+e279y5M+6///7o2bNnnHXWWSlvDgAAwB7l/ZqrJUuWxMaNGyPib0eUstlsfP/7389dPm3atNz3l156afTq1StOPPHEqKioiLfffjuWL18eq1evjuHDh8eFF17YZN+XXXZZPP7443HLLbdETU1NDBgwIFasWBFLly6NMWPGxGmnndZk/A033BATJ06MKVOmxCWXXBLl5eWxdOnSeOGFF+Kmm26Knj175nvzAAAA9knecfXwww/HU0891WTbHXfckft+97gaPXp0/OY3v4lFixbFO++8EyUlJXHcccfF9ddfHxdeeGGUlJQ02U+PHj1i4cKFMXv27Hjsscdi8eLF0a9fv7j22mtj8uTJzeYyePDgWLRoUdx+++0xd+7c2LFjR1RWVsadd94Zo0aNyvemAQAA7LO84+r+++/f67FTp07NvRvg3jrssMNixowZMWPGjL0aP3DgwGZv9w4AALC/FeQNLQAAAA404goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQV3CAyWQyhZ4CAMBBSVzRoe3alS30FNqdrl27FnoKAAAHpbw/RBjak6KiTNz84GtRvam+0FNpN4YP6Bn/b9SRhZ4GAMBBR1zR4VVvqo9XNtYVehrtxlG9uxR6CgAAByWnBQIAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBEBERmUym0FMAgA5NXAEc5Mp7FMeuXdno2rVroafSLu3alS30FADoIIrzvcLdd98da9eujbVr10Z1dXUUFRXF2rVr9zh+586dMW/evHj44YejpqYmysrKYsSIETF9+vQoLy9vNn7z5s0xe/bsWL58eWzZsiX69esX48aNi0mTJkVxcfPprlu3LmbPnh3PPPNM7NixIyorK2Pq1KkxcuTIfG8awEGpe2mnKCrKxM0PvhbVm+oLPZ12pf8RXeIb4z9W6GkA0EHkHVe33XZbHHLIITFo0KDYtm1bvP322x86/vrrr49ly5bFmWeeGVOmTIkNGzbEvffeG88++2w8+OCD0a1bt9zYrVu3xsSJE2P9+vVxwQUXxIABA2LFihVx6623xquvvhozZ85ssu9169bFhAkTonPnzjFp0qQoLy+PZcuWxZVXXhkzZ86MsWPH5nvzAA5a1Zvq45WNdYWeBgB0WHnH1a9+9avo379/RERcdNFFHxpXf/zjH2PZsmVx1llnxV133ZXbPnjw4Lj66qtj3rx5cdVVV+W2z507N15++eW47rrrYtKkSRERce6550bPnj1jwYIFMXbs2Bg+fHhu/I033hh1dXVx3333xUknnRQREePGjYvzzjsvZs6cGaNGjYoePXrkexMBAADylvdrrhrDam8sXbo0IiIXSo1Gjx4d/fr1y12++/jS0tKYMGFCk+2N11+yZElu24YNG+Lpp5+O4cOH58IqIqKkpCQuuuiieOedd2L58uV7PVcAAIDWaNM3tFi9enUUFRXFySef3OyyoUOHRnV1dWzZsiUiIt56662oqamJgQMHNntR9VFHHRW9e/eO5557Lret8fthw4a1uO+IiDVr1iS6JQAAAB8u79MC81FbWxvl5eXRuXPnZpf16dMnN6asrCxqa2sjIqKioqLFfVVUVER1dXWTfe++nw+O3X3Mvshms7Ft27Z9vn4qdXV1Tb7yfzKZTJSWlhZ6GsBBoK6uLrJZ7xrYyGMT+bJmyFd7WjPZbHavP66kTeNq+/btceihh7Z4WZcuXXJjdv/aUog1jt/9zm38vqXxjftuzT9GQ0NDvPjii/t8/dSqqqoKPYV2p7S0NE444YRCTwM4CKxfv75dPMC3Nx6byJc1Q77aw5ppaGjI9cVHadO46tq1azQ0NLR4WX19fW7M7l8/bPzuRykav29pfOO+W3NUo3PnzjFo0KB9vn4qdXV1UVVVFcccc4yjNB/gA0+B/eXYY4915Go3HpvIlzVDvtrTmtnTwZ+WtGlcVVRURFVVVTQ0NDSb1BtvvJEbs/vXPZ3KV1tb2+QUwMbxjfv54Njdx+yLTCbT5G3iC620tLRdzQfgYFLoB/b2ymMT+bJmyFd7WDP5/EK/Td/QYsiQIbFr165YvXp1s8tWrlwZ/fv3j7KysoiI6NWrV/Tt2zfWrVuXO0WwUU1NTbz55psxZMiQ3LbGdwhcuXJls32vWrWqyRgAAIC21qZxNWbMmIiImDdvXpPtTzzxRNTU1OQub3TOOedEXV1dLFq0qMn2+fPnN9lfRMTRRx8dw4YNi6eeeiqef/753PadO3fG/fffHz179oyzzjor6e0BAADYk7xPC1yyZEls3LgxIv52RCmbzcb3v//93OXTpk3LfX/GGWfE2WefHY8++mhcccUVMWLEiNiwYUPcc889cfzxxzf7/KvLLrssHn/88bjllluipqYmBgwYECtWrIilS5fGmDFj4rTTTmsy/oYbboiJEyfGlClT4pJLLony8vJYunRpvPDCC3HTTTdFz5498715AAAA+yTvuHr44YfjqaeearLtjjvuyH2/e1xFRMyaNSsqKyvjkUceie985ztRVlYWY8aMienTp0f37t2bjO3Ro0csXLgwZs+eHY899lgsXrw4+vXrF9dee21Mnjy52VwGDx4cixYtittvvz3mzp0bO3bsiMrKyrjzzjtj1KhR+d40AACAfZZ3XN1///15jS8pKYnLL788Lr/88r0af9hhh8WMGTNixowZezV+4MCBMWfOnLzmBAAAkFqbvuYKAADgYCGuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAsVt/RcMGDBgj5f97Gc/i8rKytyfd+7cGfPmzYuHH344ampqoqysLEaMGBHTp0+P8vLyZtffvHlzzJ49O5YvXx5btmyJfv36xbhx42LSpElRXNzmNw0AACBnvxTIqaeeGuedd16z7UceeWSTP19//fWxbNmyOPPMM2PKlCmxYcOGuPfee+PZZ5+NBx98MLp165Ybu3Xr1pg4cWKsX78+LrjgghgwYECsWLEibr311nj11Vdj5syZbX67AAAAGu2XuDr66KNjzJgxHzrmj3/8YyxbtizOOuusuOuuu3LbBw8eHFdffXXMmzcvrrrqqtz2uXPnxssvvxzXXXddTJo0KSIizj333OjZs2csWLAgxo4dG8OHD2+bGwQAAPAB++01Vzt27IitW7fu8fKlS5dGRORCqdHo0aOjX79+uct3H19aWhoTJkxosr3x+kuWLEkwawAAgL2zX+Lq8ccfj0984hNxyimnxKmnnhpf//rXY8OGDU3GrF69OoqKiuLkk09udv2hQ4dGdXV1bNmyJSIi3nrrraipqYmBAwdG165dm4w96qijonfv3vHcc8+11c0BAABops1PCzzxxBNj9OjRccwxx0RDQ0M888wz8dBDD8Xvfve7WLhwYRx33HEREVFbWxvl5eXRuXPnZvvo06dPbkxZWVnU1tZGRERFRUWLf2dFRUVUV1e3at7ZbDa2bdvWqn2kUFdX1+Qr/yeTyURpaWmhpwEcBOrq6iKbzRZ6Gu2GxybyZc2Qr/a0ZrLZbGQymb0a2+Zx9fDDDzf589lnnx2f//znY+rUqfHv//7vMXfu3IiI2L59exx66KEt7qNLly65Mbt/bSnEGse39h+ioaEhXnzxxVbtI6WqqqpCT6HdKS0tjRNOOKHQ0wAOAuvXr28XD/Dtjccm8mXNkK/2sGYaGhpyPfJRCvJ+5Z/73OfiE5/4RPzv//5v1NfXR5cuXaJr167R0NDQ4vj6+vqIiNwpgI1fP2x8a49odO7cOQYNGtSqfaRQV1cXVVVVccwxxzhK8wF7+xsEgNY69thjHbnajccm8mXNkK/2tGb2dECnJQX7MKijjjoqVq9eHVu2bIk+ffpERUVFVFVVRUNDQ7Mb8MYbb0TE/50G2Pi18fTAD6qtrc2dSrivMplMk7d+L7TS0tJ2NR+Ag0mhH9jbK49N5MuaIV/tYc3k8wv9/fZugR9UVVUVJSUluQ8HHjJkSOzatStWr17dbOzKlSujf//+UVZWFhERvXr1ir59+8a6detypwg2qqmpiTfffDOGDBnS5rcBAACgUZvG1ebNm1vc/uijj8YLL7wQn/70p3NHqRo/B2vevHlNxj7xxBNRU1PT7HOyzjnnnKirq4tFixY12T5//vwm+wMAANgf2vS0wLvuuiueffbZ+NSnPhVHHnlk7NixI5599tl44oknonfv3vHNb34zN/aMM86Is88+Ox599NG44oorYsSIEbFhw4a455574vjjj2/2+VeXXXZZPP7443HLLbdETU1NDBgwIFasWBFLly6NMWPGxGmnndaWNw0AAKCJNo2rT37yk/Hqq6/Gz372s9i8eXNks9no169fXHLJJXHZZZfF4Ycf3mT8rFmzorKyMh555JH4zne+E2VlZTFmzJiYPn16dO/evcnYHj16xMKFC2P27Nnx2GOPxeLFi6Nfv35x7bXXxuTJk9vyZgEAADTTpnE1YsSIGDFixF6PLykpicsvvzwuv/zyvRp/2GGHxYwZM2LGjBn7OkUAAIAkCvaGFgAAAAcScQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrACAvmUwmSkpKCj0NgHZHXAHAHpT3KI5du7KFnka7U1paGiecMDgymUyhpwLQrhQXegIA0F51L+0URUWZuPnB16J6U32hp9Nu9D+iS3xj/Mdix45CzwSgfRFXAPARqjfVxysb6wo9DQDaOacFAgAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFx1ACUlJZHJZAo9DQAA4EMUF3oCfLhMJhMnnDA4ios7FXoqAADAhxBXHUBxcae4+cHXonpTfaGn0q4MH9Az/t+oIws9DQAAiAhx1WFUb6qPVzbWFXoa7cpRvbsUegoAAJDjNVcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAOyTTCZT6CkAtCviCgDIS3mP4ti1Kxtdu3Yt9FTapV27soWeAlAgxYWeAADQsXQv7RRFRZm4+cHXonpTfaGn0670P6JLfGP8xwo9DaBAxBUAsE+qN9XHKxvrCj0NgHbDaYEAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAG0qk8lESUlJoacBbU5cAQAkUt6jOHbtyhZ6Gu1OaWlpnHDC4MhkMoWeCrSp4kJPAADgQNG9tFMUFWXi5gdfi+pN9YWeTrvR/4gu8Y3xH4sdOwo9E2hb4goAILHqTfXxysa6Qk8D2M+cFggAAJCAuAIAAEhAXAEAACQgrgAAABIQVwAAAAmIKwAAgATEFQAAQALiCgAAIAFxBQAAkIC4AgAASEBcAQAAJCCuAAAAEhBXAADsF5lMptBTgDYlrgAAaFPlPYpj165sdO3atdBTaZd27coWegokUlzoCQAAcGDrXtopiooycfODr0X1pvpCT6dd6X9El/jG+I8VehrtTiaTiZKSkkJPI2/iCgCA/aJ6U328srGu0NNoVxqP6hUVOWVyd6WlpXHCCYNjx46GQk8lL+IKAAAKxFG9ljUe0duxo9AzyU+Hj6snnngifvSjH8Wf/vSnKCkpiVNOOSWuueaaqKysLPTUAABgrziqd2Do0G9o8dBDD8XXvva1qKuri69//etxxRVXxEsvvRTnn39+vPTSS4WeHgAAcBDpsEeu/vrXv8asWbOioqIiFi1aFD169IiIiC996Uvx5S9/OW666aa47777CjxLAADgYNFhj1wtX748tm7dGueee24urCIi+vbtG6NHj44nn3wyXn/99QLOEAAAOJh02LhavXp1REQMHTq02WWN29asWbNf5wQAABy8MtlstkN+atkVV1wRv/nNb+IXv/hFHHfccU0u+5//+Z+YOnVqfPOb34yLL744732fdNJJ8f7770dFRUWq6e6zbDYbRUVF8df3dsbO9zvkP1Wb6VJSFD1KO7lvPsD9smfum5a5X/bMfdMy98ueuW9a5n7ZM/dNy4o7ZeLQ7sWxa9euyGQK+zb1tbW10alTp706cNNhX3NVV/e3d1Pp3Llzs8sat23fvn2f9t2lS5doaGgo+D9kROTmcGj3DvtP1ebcNy1zv+yZ+6Zl7pc9c9+0zP2yZ+6blrlf9sx907KiosKfaFdcXNxic7Q4to3n0mZKS0sjIqKhofkHizVu69q16z7t++mnn973iQEAAAelwqfgPurTp09E/O0w3Qc1bmsPp/UBAAAHhw4bV0OGDImIiJUrVza7bNWqVRHxt9dOAQAA7A8dNq5GjhwZ3bt3j4ceeii2bt2a275x48Z47LHH4rTTTosjjzyygDMEAAAOJh323QIjIhYvXhzf/va3o7KyMsaPHx8NDQ2xYMGC2Lx5cyxatCgGDhxY6CkCAAAHiQ4dVxERjz32WMydOzf+9Kc/RUlJSZx66qkxffp0YQUAAOxXHT6uAAAA2oMO+5orAACA9kRcAQAAJCCuAAAAEhBXAAAACYgrAACABMQVAABAAsWFnsDB6oknnogf/ehHuc/nOuWUU+Kaa66JysrKvbp+XV1dfO9734tf/OIXsWnTpjjiiCPiy1/+ckybNi1KS0vbePYUQmvWzH//93/H8uXLY9WqVbFx48bo0qVLfOxjH4tzzz03vvKVr0RxsR8FB6LW/pzZ3Ysvvhjjxo2LnTt3xs033xxjxoxpgxlTaCnWzAsvvBBz5syJZ555Jv76179GeXl5DB48OG644YY46qij2nD2FEJr18y6detizpw5sXr16njzzTfj8MMPj8GDB8eUKVNi2LBhbTx79qe777471q5dG2vXro3q6uooKiqKtWvX5r2f9v4c2OdcFcBDDz0UN9xwQ1RWVsb48eOjvr4+FixYEH/9619j0aJFMWDAgA+9/vvvvx+XXHJJPPXUUzFmzJgYPnx4rFu3LhYtWhTDhw+P+fPnR1GRg5IHktaumb/7u7+L0tLSGDlyZBx33HHx7rvvxs9//vN4/vnn43Of+1zMmTMnMpnMfro17A+tXTO727lzZ5x33nmxfv362LZtm7g6QKVYM48++mh84xvfiIEDB8YXv/jFOOyww+Ltt9+ONWvWxBVXXBGDBw/eD7eE/aW1a+a5556LCy+8MMrKyuK8886LioqK2LhxY/z4xz+Ot99+O374wx/Gpz/96f10a2hrAwYMiEMOOSQGDRoUr776arz99tt5x1WHeA6cZb/asmVLdtiwYdnPfvaz2XfffTe3vaamJnvyySdnL7rooo/cx0MPPZStrKzM3njjjU22z507N1tZWZn96U9/mnraFFCKNfOHP/whu2vXribbdu7cmZ0wYUK2srIy+9vf/jb5vCmcFGtmd3PmzMkOHTo0+73vfS9bWVmZXbJkSeopU2Ap1syrr76aPemkk7L/9E//lH3//ffbcrq0AynWzLXXXputrKzMvvTSS022P//889nKysrs1772teTzpnBee+213PcTJ07MDho0KO99dITnwA5v7GfLly+PrVu3xrnnnhs9evTIbe/bt2+MHj06nnzyyXj99dc/dB9Lly6NiIhJkyY12X7BBRdE165dY8mSJcnnTeGkWDOnn356syNTnTp1ii9+8YsREfHSSy+lnzgFk2LNNFq/fn1897vfjX/8x3+MioqKtpoyBZZizcydOzfef//9uO6666KoqCjq6uqioaGhradOgaRYM1u3bo2IiCOOOKLJ9j59+kREtItTvEinf//+rd5HR3gOLK72s9WrV0dExNChQ5td1rhtzZo1e7x+NpuNNWvWxBFHHBH9+vVrclnXrl1j0KBBH3p9Op7WrpkP88Ybb0RExOGHH76Ps6M9SrVmstlsfPOb34yBAwfGhRdemHaStCsp1sxvf/vb+PjHPx6rV6+Ov//7v4+TTz45PvGJT8T48ePjySefTD9pCirFmmk85e/aa6+N1atXxxtvvBErV66Mr3/963HooYfG5MmTE8+ajqyjPAcWV/tZ45PZln4D3LittrZ2j9ffsmVL1NXV7fE3yH369ImtW7fmfhtEx9faNbMntbW18eCDD8ahhx4aI0aMaN0kaVdSrZmFCxfGc889FzfeeGPhz2GnTbV2zbz77rvx5ptvxqZNm+Kqq66KT33qU/Hd7343rrnmmnj55Zdj8uTJ8dRTT7XN5CmIFD9nJkyYEFOnTo1nn302zjvvvPjsZz8b559/fvzlL3+JH//4x3m9NpQDX0d5Duwtwvazurq6iIjo3Llzs8sat23fvn2P12+8rKXrR0R06dIl9/fsfpiejqu1a6Yl7733XkybNi22bt0ad955Z5SVlbV6nrQfKdbMxo0b47bbbovJkyd7gnMQaO2aee+99yLib09+Lr/88rjmmmtyl5144olxySWXxH/+53/G4sWLU06bAkrxc6aoqCj69OkTAwcOjJEjR8YxxxwTVVVVMXfu3Lj00kvj3nvvbXaEgoNXR3kOLK72s8bzh1s6D71xW9euXfd4/cbL9nQee319fZO/h46vtWvmg957772YOnVqrF27Nv7lX/4lvvCFL6SZKO1GijXzrW99K3r16hVXXnll+gnS7rR2zTQ+qYmIGDt2bJPLTj/99Ojbt2+sXr066urqPD4dIFL8nLntttti/vz58dOf/rTJW7d/+tOfjrFjx8bNN98cd9xxR8JZ05F1lOfAzvPYzxpfpNnSofLGbR/2ovGysrIoLS3d46H2N954I3r06OGo1QGktWtmd1u3bo1LL700nnnmmfjXf/1Xr6M5QLV2zfzqV7+K3/3udzFlypSora2N1157LV577bX4y1/+EhERf/nLX+K1117L/eaaji/FY1O3bt0iIqJ3797NLu/du3fs2rUr3nnnnRTTpR1o7ZrZsWNH3HPPPfHxj3+82WdiDRgwID7+8Y97rR5NdJTnwOJqPxsyZEhERKxcubLZZatWrYqIiJNOOmmP189kMnHiiSfGpk2boqampsll27dvjxdffPFDr0/H09o10+jdd9+NKVOmxKpVq+Lf/u3f4vzzz086T9qP1q6Zxp8t3/rWt2LUqFG5/2699daIiPiP//iPGDVqVKxYsSLxzCmUFI9NjZe39MTn9ddfj+LiYqcgH0Bau2Y2b94cO3bsiPfff7/Fy3fu3LnHyzg4dZTnwOJqPxs5cmR07949HnrooSYvuNu4cWM89thjcdppp8WRRx4ZEX87Z/SVV16JTZs2NdlH44d3zp8/v8n2RYsWxfbt23245wEmxZp59913Y/LkybFmzZqYOXNmjBs3br/eBvav1q6ZM888M+64445m/zUe6bzooovijjvuiBNOOGH/3jDaTIqfM1/96lcjIuKBBx5osv3Xv/51bNq0KU4//fQmpw/SsbV2zfTq1SvKy8tj/fr1uRhrtHLlyqiqqsoFHAefjvwcOJPNZrOFnsTBZvHixfHtb38794nmDQ0NsWDBgti8eXMsWrQoBg4cGBERTz75ZFx88cXx1a9+NWbNmpW7/vvvvx8XX3xxPP300/GVr3wlTj311HjppZdi4cKFccopp8Q999wTnTp1KtTNow20ds38wz/8Qzz//PMxYsSIGD16dLP9DxgwILcPDgytXTMteeSRR+L666+Pm2++uV08gJFWa9fMrl274tJLL43f//738cUvfjE++clPxp///OdYsGBBdOnSJRYvXhzHH398oW4ebaC1a+aBBx6IGTNmRLdu3eL888/PvaHF4sWL4/33348FCxYIrAPIkiVLYuPGjRER8ZOf/CRef/31+NrXvpa7fNq0abnvO/JzYG9oUQDnn39+lJWVxdy5c+OWW26JkpKSOPXUU2P69Ol79QS3U6dOcffdd8f3vve9+OUvfxk///nPo3fv3jFp0qS48sorC76oSK+1a+b555+PiL996OPy5cubXX7VVVeJqwNMa9cMB5/WrpmioqK466674oc//GEsW7Ysli9fHt27d4+RI0fG1VdfHccee+x+uBXsT61dMxdeeGH06dMn7r///vjJT34S7733XpSVlcVnPvOZmDZtmp9VB5iHH3642Ucy7P6GJbvH1Z50hOfAjlwBAAAk4DVXAAAACYgrAACABMQVAABAAuIKAAAgAXEFAACQgLgCAABIQFwBAAAkIK4AAAASEFcAAAAJiCsAAIAExBUAAEAC4goAACABcQUAAJDA/weNWStIiH7GRAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_rouge.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "0cdd0b6b-eed9-4d51-8fa5-1dfe264bfdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3173186791150795"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_rouge.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc68af07-79e9-42fe-82f3-2068c049d0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06896550360234334"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "bleu_scorer = BLEU()\n",
    "\n",
    "hypothesis = \"Soft tissue nodule within the right submandibular space with mild enhancement similar to the adjacent submandibular gland. These findings may represent reactive changes related to prior treatment. No evidence of lymphadenopathy. Please see CT for further evaluation.\"\n",
    "reference = \"Right submandibular space adenopathy compatible with the stated history of lymphoma. The dominant lesion is difficult to separate from the adjacent submandibular gland and may have invaded it or arisen from it. Smaller suspicious lymph nodes are evident elsewhere in the upper right neck as above.\"\n",
    "\n",
    "score = bleu_scorer.sentence_score(\n",
    "    hypothesis=hypothesis,\n",
    "    references=[reference],\n",
    ")\n",
    "\n",
    "score.score/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acc6f92-7cbd-4f04-82b6-d3d2d43c2f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26666666171022224"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "hypothesis = \"Soft tissue nodule within the right submandibular space with mild enhancement similar to the adjacent submandibular gland. These findings may represent reactive changes related to prior treatment. No evidence of lymphadenopathy. Please see CT for further evaluation.\"\n",
    "reference = \"Right submandibular space adenopathy compatible with the stated history of lymphoma. The dominant lesion is difficult to separate from the adjacent submandibular gland and may have invaded it or arisen from it. Smaller suspicious lymph nodes are evident elsewhere in the upper right neck as above.\"\n",
    "\n",
    "score = rouge_scorer.get_scores(\n",
    "    hyps=hypothesis,\n",
    "    refs=reference,\n",
    ")\n",
    "score[0][\"rouge-l\"][\"f\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4356af06-d613-4ae5-a0af-b54dc99b768b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35483870480749224"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "hypothesis = \"Stable ventricular size and configuration without evidence for acute intracranial hemorrhage. No significant interval change of right frontal lobe subarachnoid hemorrhage. Stable CT findings related to suboccipital craniectomy with an otherwise small posterior fossa and mildly low-lying cerebellar tonsils.\"\n",
    "reference = \"Right parietal approach ventricular shunt catheter, unchanged in position. Unchanged ventricular size and configuration. No intracranial hemorrhage or midline shift. Suboccipital craniectomy with slightly low-lying cerebellar tonsils, unchanged.\"\n",
    "\n",
    "score = rouge_scorer.get_scores(\n",
    "    hyps=hypothesis,\n",
    "    refs=reference,\n",
    ")\n",
    "score[0][\"rouge-l\"][\"f\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236eb6a-3ca8-44f4-96b6-d1fab0d67bff",
   "metadata": {},
   "source": [
    "## reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "80f8058c-cc70-4342-812f-eae3aa4d884f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/tmp/ipykernel_18147/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2057017563.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/var/tmp/ipykernel_18147/2057017563.py'</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>No module named <span style=\"color: #008000; text-decoration-color: #008000\">'trl'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/tmp/ipykernel_18147/\u001b[0m\u001b[1;33m2057017563.py\u001b[0m:\u001b[94m4\u001b[0m in \u001b[92m<module>\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/var/tmp/ipykernel_18147/2057017563.py'\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'trl'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model\n",
    "from trl.core import respond_to_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4590466d-f9a8-47cc-b9c5-44382a32a71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7999999952000001,\n",
       " 0.999999995,\n",
       " 0.2727272697520661,\n",
       " 0.05555555358024698,\n",
       " 0.34782608408317583]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_score[639]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "p39",
   "name": "common-cu110.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m107"
  },
  "kernelspec": {
   "display_name": "p39",
   "language": "python",
   "name": "p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
